# Natural language processing course: `Analysis and Comparison of Translation Errors and Biases in LLMs`

1 ABOUT OUR PROJECT

Our project investigates gender bias in Large Language Models (LLMs) when translating from English to Slovene, focusing on how ambiguous pronouns are translated. English and Slovene have different gender marker structures, and we aim to analyze how LLMs may introduce or reinforce gender biases in these translations.
We will use the WinoBias dataset, which contains gender-biased sentences, to study how LLMs handle pronouns in ambiguous contexts. The analysis will involve one open-source model and one closed-source model.
This analysis is crucial for understanding how LLMs handle gendered language, ensuring fairer, less biased translations in multilingual contexts.



2 PROJECT MEMBERS

Pia Polutnik

Tajda Hladnik

Marko Stoklas 



3 REFERENCES

Roberto Navigli, Simone Conia, and Bj√∂rn Ross. 2023. Biases in Large Language Models: Origins, Inventory, and Discussion. J. Data and Information Quality 15, 2, Article 10 (June 2023).
https://doi.org/10.1145/3597307

Barclay, P. J., & Sami, A. (2024). Investigating Markers and Drivers of Gender Bias in Machine Translations. arXiv.Org, abs/2403.11896. 
https://doi.org/10.48550/arxiv.2403.11896

Hadas Kotek, Rikker Dockum, David Sun. 2023. Gender bias and stereotypes in Large Language Models. 
https://dl.acm.org/doi/abs/10.1145/3582269.3615599
